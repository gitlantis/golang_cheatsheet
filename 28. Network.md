### OSI  
The Open Systems Interconnection (OSI) model describes seven layers that computer systems use to communicate over a network. It was the first standard model for network communications, adopted by all major computer and telecommunication companies in the early 1980s

The modern Internet is not based on OSI, but on the simpler TCP/IP model. However, the OSI 7-layer model is still widely used, as it helps visualize and communicate how networks operate, and helps isolate and troubleshoot networking problems.

OSI was introduced in 1983 by representatives of the major computer and telecom companies, and was adopted by ISO as an international standard in 1984.
![[Pasted image 20230504090400.png]]
We’ll describe OSI layers “top down” from the application layer that directly serves the end user, down to the physical layer.

**7. Application Layer**

The application layer is used by end-user software such as web browsers and email clients. It provides protocols that allow software to send and receive information and present meaningful data to users. A few examples of application layer protocols are the [Hypertext Transfer Protocol](https://www.imperva.com/learn/performance/http2/) (HTTP), File Transfer Protocol (FTP), Post Office Protocol (POP), Simple Mail Transfer Protocol (SMTP), and Domain Name System (DNS).

**6. Presentation Layer**

The presentation layer prepares data for the application layer. It defines how two devices should encode, encrypt, and compress data so it is received correctly on the other end. The presentation layer takes any data transmitted by the application layer and prepares it for transmission over the session layer.

**5. Session Layer**

The session layer creates communication channels, called sessions, between devices. It is responsible for opening sessions, ensuring they remain open and functional while data is being transferred, and closing them when communication ends. The session layer can also set checkpoints during a data transfer—if the session is interrupted, devices can resume data transfer from the last checkpoint.

**4. Transport Layer**

The transport layer takes data transferred in the session layer and breaks it into “segments” on the transmitting end. It is responsible for reassembling the segments on the receiving end, turning it back into data that can be used by the session layer. The transport layer carries out flow control, sending data at a rate that matches the connection speed of the receiving device, and error control, checking if data was received incorrectly and if not, requesting it again.

**3. Network Layer**

The network layer has two main functions. One is breaking up segments into network packets, and reassembling the packets on the receiving end. The other is routing packets by discovering the best path across a physical network. The network layer uses network addresses (typically Internet Protocol addresses) to route packets to a destination node.

**2. Data Link Layer**

The data link layer establishes and terminates a connection between two physically-connected nodes on a network. It breaks up packets into frames and sends them from source to destination. This layer is composed of two parts—Logical Link Control (LLC), which identifies network protocols, performs error checking and synchronizes frames, and Media Access Control (MAC) which uses MAC addresses to connect devices and define permissions to transmit and receive data.

**1. Physical Layer**

The physical layer is responsible for the physical cable or wireless connection between network nodes. It defines the connector, the electrical cable or wireless technology connecting the devices, and is responsible for transmission of the raw data, which is simply a series of 0s and 1s, while taking care of bit rate control.

### Advantages of OSI Model

**The OSI model helps users and operators of computer networks:**

-   Determine the required hardware and software to build their network.
-   Understand and communicate the process followed by components communicating across a network. 
-   Perform troubleshooting, by identifying which network layer is causing an issue and focusing efforts on that layer.
-
#### OSI vs. TCP/IP Model
![[Pasted image 20230504090512.png]]
The [Transfer Control Protocol/Internet Protocol](https://www.imperva.com/learn/application-security/tcp-transmission-control-protocol/) (TCP/IP) is older than the OSI model and was created by the US Department of Defense (DoD). A key difference between the models is that TCP/IP is simpler, collapsing several OSI layers into one:

-   OSI layers 5, 6, 7 are combined into one Application Layer in TCP/IP
-   OSI layers 1, 2 are combined into one Network Access Layer in TCP/IP – however TCP/IP does not take responsibility for sequencing and acknowledgement functions, leaving these to the underlying transport layer.

Other important differences:

-   TCP/IP is a functional model designed to solve specific communication problems, and which is based on specific, standard protocols. OSI is a generic, protocol-independent model intended to describe all forms of network communication.
-   In TCP/IP, most applications use all the layers, while in OSI simple applications do not use all seven layers. Only layers 1, 2 and 3 are mandatory to enable any data communication.

### HTTP1/HTTP2
HTTP/1.1 has been around for more than a decade. With Google’s SPDY leading the way in 2015, the IETF (Internet Engineering Task Force) gave us HTTP/2, which introduces several features to reduce page load times. Let’s compare HTTP2 Vs. HTTP1.1 in detail.

HTTP/2 achieves faster webpage loading without performance optimizations that require extensive human efforts in terms of development. It significantly reduces the complexities that had crept into HTTP/1.1 and gives us a robust protocol which, though not without its flaws, will perhaps stand the test of time. Before making this leap forward, let’s trace our steps back to when the internet was in its infancy to understand how the different versions evolved into the current form.

## The Beginnings of HTTP & The Internet

Our story begins in 1969, with a program called Advanced Research Projects Agency Network (ARPANET). ARPANET used packet switching and allowed multiple computers to communicate with each other on a single network. However, this was just a by-product. The original intention behind ARPANET was to design a time-sharing system that allowed research institutes to share their computer resources for effective utilization of processing power.
Before then, sometime during the 19th century, the seeds for the existence of the internet as we know it today had already been sown with the invention of electricity and the telegraph. With Morse sending the first telegraphic message in 1844 and the first cable being laid across Atlantic, the telegraph network infrastructure had spread its roots through continents and across oceans. In years to come, this would become the very foundation on which the internet was built. In 1973, Kahn and Cerf designed the TCP/IP protocol suite which was adopted by ARPANET a decade later, and from this point on, we witness the development of an interconnected network. The internet took a more recognizable form with the invention of the World Wide Web (that used HTTP as its underlying protocol) by Tim Berners-Lee and the Commercial Internet eXchange (CIX) that allowed a free exchange of TCP/IP traffic between ISPs.

## Evolution of HTTP

HTTP (Hypertext Transfer Protocol) is a set of rules that runs on top of the TCP/IP suite of protocols and defines how files are to be transferred between clients and servers on the world wide web.

![HTTP Protocol Process](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/http-protocol.png)

## The Beginning of HTTP: Version 0.9 & 1.0

In the earliest phase (HTTP/0.9), the HTTP protocol did not use headers and only transmitted plain HTML files. It was a one-line protocol only supporting the GET method.

![Figure 2: HTTP/0.9 - Example request and response](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/http-0-9.png)

As the need to exchange more than just plain HTML emerged along with the client and server applications becoming more mature, HTTP/1.0 (between 1991-1996) introduced several new features.

## Key Features of HTTP/1.0:

-   The concept of headers both for requests (from the client machine) as well as responses (from servers) was introduced. The use of headers such as GET, POST, HEAD added extended flexibility, none of which was possible with the earlier version.
-   Version information was now included.
-   It allowed a single request/response for every TCP connection.
-   Status codes were used to indicate successful requests and to indicate transmission errors.
-   The content-type header made it possible to send files other than plain HTML, including scripts and media.

## Created for Added Security: HTTPS

In 1994, Netscape Communications created HTTPS (Hypertext Transfer Protocol Secure) to be used with SSL for its web browser, Netscape Navigator. The need for encrypted transmission channels emerged as the applications being designed shifted towards a more commercial market where advertisers, unknown individuals, and cybercriminals could have easy access to personal data. SSL evolved into TLS with TLS version 1.2 and 1.3 being used currently.

## The Protocol Serving Netizens for Over 15 Years: HTTP/1.1

HTTP/1.1, the first standardized version of HTTP, was introduced in 1997. It presented significant performance optimizations (over HTTP/0.9 and HTTP/1.0) and transformed the way requests and responses were exchanged between clients and servers.

![Figure 3: HTTP/1.1 - Example request and response](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/http-1-1.png)

## Key Features of HTTP/1.1:

-   It was no longer required for each connection to be terminated immediately after every request was served with a response; instead, with the keep-alive header, it was possible to have persistent connections. It allowed multiple requests/responses per TCP connection.
-   The Upgrade header was used to indicate a preference from the client that made it possible to switch to a more preferred protocol if found appropriate by the server.
-   HTTP/1.1 provided support for chunk transfers that allowed streaming of content dynamically as chunks and for additional headers to be sent after the message body. This enhancement was particularly useful in cases where values of a field remained unknown until the content had been produced. For example, when the content had to be digitally signed, it was not possible to do so before the entire content gets generated.
-   Other features that reinforced its stability were introduced such as:
    -   pipelining (the second request is sent before the response to the first is adequately served)
    -   content negotiation (an exchange between client and server to determine the media type, it also provides the provision to serve different versions of a resource at the same URI)
    -   cache control (used to specify caching policies in both requests and responses)

## The Protocol Designed to Speed Up Today’s Complex Web pages: HTTP/2

At the beginning of 2010, Google introduced an experimental protocol, SPDY, which supported multiplexing (multiple requests/responses sent and received asynchronously over a single TCP connection) but as it gained traction IETF’s HTTP Working Group came up with HTTP/2 in 2015, which is based on the SPDY protocol.

## Key Features of HTTP/2:

-   It introduces the concept of a server push where the server anticipates the resources that will be required by the client and pushes them prior to the client making requests. The client retains the authority to deny the server push; however, in most cases, this feature adds a lot of efficiency to the process.

![Figure 4: Server push in HTTP/2](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/server-push-in-http-2.png)

-   Introduces the concept of multiplexing that interleaves the requests and responses without head-of-line blocking and does so over a single TCP connection.

![Figure 5: Multiplexing in HTTP/2](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/multiplexing-http-2.png)

-   It is a binary protocol i.e. only binary commands in the form of 0s and 1s are transmitted over the wire. The binary framing layer divides the message into frames that are segregated based on their type – Data or Header. This feature greatly increases efficiency in terms of security, compression and multiplexing.

![Figure 6: Binary Framing Layer](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/binary-framing-layer-1024x529.png)

![Figure 7: HTTP/2 - Binary Traffic](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/http-2-binary-traffic.png)

-   HTTP/2 uses HPACK header compression algorithm that is resilient to attacks like CRIME and utilizes static Huffman encoding.

HTTP/3, the next version in the series, is based on Google’s QUIC which, unlike its precursors is a drastic shift to UDP. Given the gradual adoption rate of HTTP/2, HTTP/3 with its security challenges (that comes into play the moment we switch from TCP to UDP) is expected to face some difficulties.

![Figure 8: Evolution of HTTP - Timeline](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/evolution-of-http.png)

## HTTP/1.x vs HTTP/2: A Comparative Study

HTTP2 Vs. HTTP1 is not a debate at all. HTTP2 is much faster and more reliable than HTTP1. HTTP1 loads a single request for every TCP connection, while HTTP2 avoids network delay by using multiplexing.

HTTP is a network delay sensitive protocol in the sense that if there is less network delay, then the page loads faster. However, an impressive increase in network bandwidth only slightly improves page load time. This is key to understanding the differences in performance efficiencies between the different versions of HTTP. Back in the day when people used dial up modems web pages were simple and it was the actual data transfer between the server and the client that contributed towards the largest chunk of the page load time. Today the actual downloading of resources from server takes a negligible portion of the total page load time due to the tremendous increase in bandwidth availability. It is the time taken to establish the TCP connection and making requests that impacts performance. It was initially recommended to use only two connections per hostname but today most browsers use six connections per hostname. When we talk about http vs http2 in terms of performance it is important to note that a lot of performance optimizations adopted by HTTP/1.1 introduced complexities in terms of developmental efforts as well as network congestion that HTTP/2 attempts to address.

The table below points out the differentiating factors between http2 vs http1:

Header CompressionHeaders are sent on every request leading to a lot of duplicate data being sent uncompressed across the wire.Header compression is included by default in HTTP/2 using HPACK.Performance OptimizationProvides support for caching to deliver pages faster.Spriting, concatenating, inlining, domain sharding are some of the optimizations used as a workaround to the ‘six connections per host’ rule.Removes the need for unnecessary optimization hacks.Protocol TypeText based protocol that is in the readable form.It is a binary protocol (HTTP requests are sent in the form of 0s and 1s). Needs to be converted back from binary in order to read it.SecuritySSL is not required but recommended. Digest authentication used in HTTP1.1 is an improvement over HTTP1.0. HTTPS uses SSL/TLS for secure encrypted communication.Though security is still not mandatory, it is mostly encrypted (though it is not enforced) since almost all clients require traffic to be encrypted. It also has some minimum standards, such as minimum key size for encryption. TLS 1.2 etc.

Header CompressionHeaders are sent on every request leading to a lot of duplicate data being sent uncompressed across the wire.Header compression is included by default in HTTP/2 using HPACK.Performance OptimizationProvides support for caching to deliver pages faster.Spriting, concatenating, inlining, domain sharding are some of the optimizations used as a workaround to the ‘six connections per host’ rule.Removes the need for unnecessary optimization hacks.Protocol TypeText based protocol that is in the readable form.It is a binary protocol (HTTP requests are sent in the form of 0s and 1s). Needs to be converted back from binary in order to read it.SecuritySSL is not required but recommended. Digest authentication used in HTTP1.1 is an improvement over HTTP1.0. HTTPS uses SSL/TLS for secure encrypted communication.Though security is still not mandatory, it is mostly encrypted (though it is not enforced) since almost all clients require traffic to be encrypted. It also has some minimum standards, such as minimum key size for encryption. TLS 1.2 etc.

Differentiator

HTTP/1.0

HTTP/1.1

HTTP/2

Year

1991

1997

2015

Key Features

For every TCP connection there is only one request and one response.  
![HTTP1 Protocol](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/http1-265x300.png)

It supports connection reuse i.e. for every TCP connection there could be multiple requests and responses, and pipelining where the client can request several resources from the server at once. However, pipelining was hard to implement due to issues such as head-of-line blocking and was not a feasible solution.  
![HTTP2 Protocol](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/http2-265x300.png)

Uses multiplexing, where over a single TCP connection resources to be delivered are interleaved and arrive at the client almost at the same time. It is done using streams which can be prioritized, can have dependencies and individual flow control. It also provides a feature called server push that allows the server to send data that the client will need but has not yet requested.  
![HTTP3 Protocol](https://cheapsslsecurity.com/p/wp-content/uploads/2019/07/http3-283x300.png)

Status Code

Can define 16 status codes; the error prompt is not specific enough.

Introduces a warning header field to carry additional information about the status of a message. Can define 24 status codes, error reporting is quicker and more efficient.

Underlying semantics of HTTP such as headers, status codes remains the same.

Authentication Mechanism

Uses basic authentication scheme which is unsafe since username and passwords are transmitted in clear text or base64 encoded.

It is relatively secure since it uses digest authentication, NTLM authentication.

Security concerns from previous versions will continue to be seen in HTTP/2. However, it is better equipped to deal with them due to new TLS features like connection error of type Inadequate_Security.

Caching

Provides support for caching via the If-Modified-Since header.

Expands on the caching support by using additional headers like cache-control, conditional headers like If-Match and by using entity tags.

HTTP/2 does not change much in terms of caching. With the server push feature if the client finds the resources are already present in the cache, it can cancel the pushed stream.

Web Traffic

HTTP/1.1 provides faster delivery of web pages and reduces web traffic as compared to HTTP/1.0. However, TCP starts slowly and with domain sharding (resources can be downloaded simultaneously by using multiple domains), connection reuse and pipelining, there is an increased risk of network congestion.

HTTP/2 utilizes multiplexing and server push to effectively reduce the page load time by a greater margin along with being less sensitive to network delays.

Header CompressionHeaders are sent on every request leading to a lot of duplicate data being sent uncompressed across the wire.Header compression is included by default in HTTP/2 using HPACK.Performance Optimization Provides support for caching to deliver pages faster. Spriting, concatenating, inlining, domain sharding are some of the optimizations used as a workaround to the ‘six connections per host’ rule.Removes the need for unnecessary optimization hacks. Protocol Type Text based protocol that is in the readable form.It is a binary protocol (HTTP requests are sent in the form of 0s and 1s). Needs to be converted back from binary in order to read it. SecuritySSL is not required but recommended. Digest authentication used in HTTP1.1 is an improvement over HTTP1.0. HTTPS uses SSL/TLS for secure encrypted communication.Though security is still not mandatory, it is mostly encrypted (though it is not enforced) since almost all clients require traffic to be encrypted. It also has some minimum standards, such as minimum key size for encryption. TLS 1.2 etc.

## How to Implement HTTP/2 on Your Website

Since using HTTP/2 is an invisible process when correctly implemented, your website may already be using it without your realization. There is an easy way to check this:

-   Open the web developer tool on the web browser (like Firefox).
-   Under the network tab, select any of the resources and check the version number under the headers tab.

While HTTP/2 does not mandate the use of SSL, it is crucial to install an SSL certificate because the leading browsers, including Firefox and Chrome, have decided to implement HTTP/2 only over TLS (HTTPS). In order to enable HTTP/2 it is essential to get an SSL/TLS certificate and make every page on the website https.

At the web server level, it could be as simple as a software update, for example, Apache began support for HTTP/2 in version 2.4.17.

## Adoption Of HTTP/2

HTTP/2 penetration on the client side is more than 70% as most major browsers support HTTP/2 and on the server side we have major tech giants like Google, Facebook, Nginx, etc. who have their own servers supporting HTTP/2. The adoption rate, [according to W3Techs](https://w3techs.com/technologies/details/ce-http2), is currently around 29% globally.

### API
#### REST API vs Web API
In the world of web development, there are several confusing words that we often hear and let them pass because we can’t wrap our heads around them. They include Web API, REST API, and SOAP API, among others. If you have been finding these words confusing, read through to understand what they mean, how they relate, and their differences.

#### What is REST API?

Before we jump right into it, let’s first understand what REST is. Contrary to the belief of many, REST is not a protocol, a tool or library, but rather an architectural style of web service that provides a channel of communication between systems or computers on the internet. It is a standard that is utilized as an architectural means of designing a Network-based software system.

Therefore a REST API is an application program interface that is backed by the architectural style of REST. It refers to tools, service or software that is based on the REST architectural principle. Although REST can be used on nearly any protocol, they take advantage of HTTP when used for web APIs. The primary advantage of REST APIs is that they offer more flexibility. In REST APIs, data is not constrained to resources or methods. Therefore, it can make multiple types of calls, return various data formats, and even change structurally with the appropriate implementation of hypermedia.

##### Examples of REST APIs

1.  Instagram API permits your applications to retrieve user tags, photos, account and much more.
2.  Twitter also provides a REST API which a developer can query to source the latest tweets, or provide a search query that will return the results in [JSON format](https://rapidapi.com/blog/api-glossary/json/).
3.  GitHub also offers super REST API that you can utilize to perform actions such as following GitHub issues, tracking user activity, and create repositories from your app.

#### REST OPTIONS
In REST **OPTIONS** is a method level annotation, this annotation indicates that the following method will respond to the HTTP OPTIONS request only. It is used to request, for information about the communication option available for a resource.

This method allows the client of the REST API to determine, which HTTP method ( [GET](https://codedestine.com/jax-rs-get-restful-web-services/), [HEAD](https://codedestine.com/rest-head-restful-web-services/), [POST](https://codedestine.com/jax-rs-post-restful-web-services/), [PUT](https://codedestine.com/jax-rs-put-restful-web-services/), [DELETE](https://codedestine.com/jax-rs-delete-restful-web-services/) ) can be used for a resource identified by requested URI, without initiating a resource request by using any particular HTTP method. Response to this method are not cacheable.

A **200 OK** response should include any header fields like Allow, that determine the communication option implemented by the server and are applicable for a resource identified by requested URI. The response body ( if any ) should also include information about the communication option available for a resource. The format for such a body is not defined by the specification, but might be defined by future extensions to HTTP. If response body is not included then value of Content-Length header field should be 0.

**Example :-**  
_200 OK_  
_Allow: HEAD,GET,PUT,DELETE,OPTIONS_

If request URI is an asterisk sign ( ***** ), then the OPTIONS method request applies to the server rather than to a specific resource. It can be used as a _**ping**_ to server for checking its capabilities.

REST OPTIONS method is also used for **CORS** ( Cross-Origin Resource Sharing ) request.

Example:
In this example of REST OPTIONS, we will hit this URL **_<base URL>/books_** to get the list of HTTP method allowed for book resource.
```java
import javax.ws.rs.OPTIONS;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
 
@Path("books")
public class OptionsMethodExample {
 
  @OPTIONS
  @Produces(MediaType.APPLICATION_JSON)
  @Path("/")
  public Response optionsForBookResource() {        
      return Response.status(200)
        .header("Allow","POST, PUT, GET")
        .header("Content-Type", MediaType.APPLICATION_JSON)
        .header("Content-Length", "0")
        .build();
  }
     
}
```
![[Pasted image 20230504143816.png]]

#### What is Web API?

Web API is basically an open-source framework that is used to write HTTP APIs. It refers to an API over the web which can be accessed using the HTTP protocol. It is important to note that it is a concept and not a technology. Developers can build Web API using a vast array of technologies such as .NET, and Java, among others. Web API can be RESTful or not. Web API implements protocol specification and thus it incorporates concepts like caching, URIs, versioning, request/response headers, and various content formats in it.

##### Examples of Web APIs

1.  Google APIs – In any area of modern technology, you can be assured that Google will set the benchmark. Their APIs include Google Analytic API, YouTube API, Blogger API, and Google Font API, among others.
2.  There are also [social media APIs](https://rapidapi.com/collection/social-media-apis) such as Twitter API, Facebook APIs, Scoop.it API and Linkedin API.

#### What is SOAP API?

SOAP (Simple Access Protocol) is a standard messaging or communication protocol system that allows processes that utilize various operating systems such as Windows and Linux to interact and communicate through HTTP and its XML. SOAP APIs are designed with the capability to create, update, recover and delete records such as passwords, leads, accounts, and custom objects. While Web API in the time of Web 1.0 was synonymous with SOAP-based web services, today in Web 2.0, the term SOAP is edging towards REST-style web resources

### WebSocket
WebSocket is a computer communications protocol, providing full-duplex communication channels over a single TCP connection. The WebSocket protocol was standardized by the IETF as RFC 6455 in 2011. The current API specification allowing web applications to use this protocol is known as WebSockets.[1] It is a living standard maintained by the WHATWG and a successor to The WebSocket API from the W3C.[2]

WebSocket is distinct from HTTP. Both protocols are located at layer 7 in the OSI model and depend on TCP at layer 4. Although they are different, RFC 6455 states that WebSocket "is designed to work over HTTP ports 443 and 80 as well as to support HTTP proxies and intermediaries", thus making it compatible with HTTP. To achieve compatibility, the WebSocket handshake uses the HTTP Upgrade header[3] to change from the HTTP protocol to the WebSocket protocol.

The WebSocket protocol enables interaction between a web browser (or other client application) and a web server with lower overhead than half-duplex alternatives such as HTTP polling, facilitating real-time data transfer from and to the server. This is made possible by providing a standardized way for the server to send content to the client without being first requested by the client, and allowing messages to be passed back and forth while keeping the connection open. In this way, a two-way ongoing conversation can take place between the client and the server. The communications are usually done over TCP port number 443 (or 80 in the case of unsecured connections), which is beneficial for environments that block non-web Internet connections using a firewall. Similar two-way browser–server communications have been achieved in non-standardized ways using stopgap technologies such as Comet or Adobe Flash Player.[4]

Most browsers support the protocol, including Google Chrome, Firefox, Microsoft Edge, Internet Explorer, Safari and Opera.[5]

Unlike HTTP, WebSocket provides full-duplex communication.[6][7] Additionally, WebSocket enables streams of messages on top of TCP. TCP alone deals with streams of bytes with no inherent concept of a message. Before WebSocket, port 80 full-duplex communication was attainable using Comet channels; however, Comet implementation is nontrivial, and due to the TCP handshake and HTTP header overhead, it is inefficient for small messages. The WebSocket protocol aims to solve these problems without compromising the security assumptions of the web.

The WebSocket protocol specification defines ws (WebSocket) and wss (WebSocket Secure) as two new uniform resource identifier (URI) schemes[8] that are used for unencrypted and encrypted connections respectively. Apart from the scheme name and fragment (i.e. # is not supported), the rest of the URI components are defined to use URI generic syntax.[9]

Using browser developer tools, developers can inspect the WebSocket handshake as well as the WebSocket frames.

### gRPC
gRPC (gRPC Remote Procedure Calls[2]) is a cross-platform open source high performance remote procedure call (RPC) framework. gRPC was initially created by Google, which used a single general-purpose RPC infrastructure called Stubby to connect the large number of microservices running within and across its data centers from about 2001.[3] In March 2015, Google decided to build the next version of Stubby and make it open source. The result was gRPC, which is now used in many organizations aside from Google to power use cases from microservices to the “last mile” of computing (mobile, web, and Internet of Things). It uses HTTP/2 for transport, Protocol Buffers as the interface description language, and provides features such as authentication, bidirectional streaming and flow control, blocking or nonblocking bindings, and cancellation and timeouts. It generates cross-platform client and server bindings for many languages. Most common usage scenarios include connecting services in a microservices style architecture, or connecting mobile device clients to backend services.[4]

gRPC's complex use of HTTP/2 makes it impossible to implement a gRPC client in the browser, instead requiring a proxy.[5]