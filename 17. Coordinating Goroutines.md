### WaitGroups

### Using Mutual Exclusion
```go
package main

import (
	"sync"
	"time"
)

var waitGroup = sync.WaitGroup{}

func doSum(count int, val *int) {
	time.Sleep(time.Second)
	for i := 0; i < count; i++ {
		*val++
	}
	waitGroup.Done()
}
func main() {
	counter := 0
	numRoutines := 3
	waitGroup.Add(numRoutines)
	for i := 0; i < numRoutines; i++ {
		go doSum(5000, &counter)
	}
	waitGroup.Wait()
	Printfln("Total: %v", counter)
}
```
***output:***
```go
Total: 12129
```
You may see a different result, and running the project repeatedly can generate a different result each time. You may get the correct result—which is 15,000, since there are three goroutines each performing 5,000 operations—but that happens rarely on my machine. This behavior can differ between operating systems. In my simple testing, I consistently encountered problems on Windows while Linux worked more often.
The problem is that the increment operator isn’t atomic, which means that it requires several steps to complete: the counter variable is read, incremented, and written. This is a simplification, but the problem is that these steps are being performed in parallel by goroutines, and they start to overlap
![[Pasted image 20230501154527.png]]
One way to solve this problem is with mutual exclusion, which ensures that a goroutine has exclusive access to the data it requires and prevents other goroutines from accessing that data.
Mutual exclusion is like checking out a book from the library. Only one person can check out the book at any given time, and all the other people who would like that book have to wait until the first person has finished, at which point the book can be checked out by someone else.

***Lock()*** - This method locks the Mutex. If the Mutex is already locked, this method blocks until it is unlocked. 
***Unlock()*** - This method unlocks the Mutex

Using a Mutex
```go
package main

import (
	"sync"
	"time"
)

var waitGroup = sync.WaitGroup{}
var mutex = sync.Mutex{}

func doSum(count int, val *int) {
	time.Sleep(time.Second)
	for i := 0; i < count; i++ {
		mutex.Lock()
		*val++
		mutex.Unlock()
	}
	waitGroup.Done()
}
func main() {
	counter := 0
	numRoutines := 3
	waitGroup.Add(numRoutines)
	for i := 0; i < numRoutines; i++ {
		go doSum(5000, &counter)
	}
	waitGroup.Wait()
	Printfln("Total: %v", counter)
}
```
A Mutex is unlocked when it is created, which means that the first goroutine that calls the Lock method won’t block and will be able to increment the counter variable. The goroutine is said to have acquired the lock. Any other goroutine that calls the Lock method will block until the Unlock method is called, known as releasing the lock, at which point another goroutine will be able to acquire the lock and proceed with its access to the counter variable. The result is that only one goroutine at a time can increment the variable
![[Pasted image 20230501154844.png]]

Performing Fewer Mutex Operations
```go
...
func doSum(count int, val *int) {
	time.Sleep(time.Second)
	mutex.Lock()
	for i := 0; i < count; i++ {
		 *val++
	}
	mutex.Unlock()
	waitGroup.Done()
}
...
```

### Using a Read-Write Mutex
A Mutex treats all goroutines as being equal and allows only one goroutine to acquire the lock. The RWMutex struct is more flexible and supports two categories of goroutine: readers and writers. Any number of readers can acquire the lock simultaneously, or a single writer can acquire the lock. The idea is that readers only care about conflicts with writers and can execute concurrently with other readers without difficulty.

***RLock()*** - This method attempts to acquire the read lock and will block until it is acquired. ***RUnlock()*** - This method releases the read lock. Lock() This method attempts to acquire the write lock and will block until it is acquired. 
***Unlock()*** - This method releases the write lock. 
***RLocker()*** - This method returns a pointer to a Locker for acquiring and releasing the read lock, as described in the “Using Conditions to Coordinate Goroutines” section.

### Contexts
Context is one of the critical features in Go that enables concurrency. In Go, “context” refers to a package that provides functionality for request-scoped values and cancelation signals across API boundaries.

The context package works simultaneously with Go's concurrency model, based on the concept of goroutines. Goroutines are lightweight threads of execution that you can create and manage efficiently, making it easy to create concurrent programs in Go.

The Methods Defined by the Context Interface
***
***Value(key)*** - This method returns the value associated with the specified key. 
***Done()*** - This method returns a channel that can be used to receive a cancelation notification. 
***Deadline()*** - This method returns the time.Time that represents the deadline for the request and a bool value that will be false if no deadline has been specified. 
***Err()*** - This method returns an error that indicates why the Done channel received a signal. The context package defines two variables that can be used to compare the error: Canceled indicates that the request was canceled, and DeadlineExeeded indicates that the deadline passed.

The context Package Functions for Creating Context Values
***
***Background()*** - This method returns the default Context, from which other contexts are derived. 
***WithCancel(ctx)*** - This method returns a context and a cancelation function, as described in the “Canceling a Request” section. 
***WithDeadline(ctx, time)*** - This method returns a context with a deadline, which is expressed using a time. Time value, as described in the “Setting a Deadline” section. 
***WithTimeout(ctx, duration)*** - This method returns a context with a deadline, which is expressed using a time. Duration value, as described in the “Setting a Deadline” section. 
***WithValue(ctx, key, val)*** - This method returns a context containing the specified key-value pair, as described in the “Providing Request Data” section.

### Once
Once is an object that will perform exactly one action.
```go
import (
	"fmt"
	"sync"
)

func main() {
	var once sync.Once
	onceBody := func() {
		fmt.Println("Only once")
	}
	done := make(chan bool)
	for i := 0; i < 10; i++ {
		go func() {
			once.Do(onceBody)
			done <- true
		}()
	}
	for i := 0; i < 10; i++ {
		<-done
	}
}
```
***output:***
```
Only once
```

### Pool
I encountered a problem in the Go Garbage Collection inside a project of mine recently. A massive amount of objects were allocated repeatedly and caused a huge workload of GC. Using `sync.Pool` I was able to decrease the allocations and GC workload.

#### What is sync.Pool?
One of the highlights of the Go 1.3 release was sync Pool. It is a component under the `sync` package to create a self-managed temporary retrieval object pool.

#### Why use sync.Pool?
We want to keep the GC overhead as little as possible. Frequent allocation and recycling of memory will cause a heavy burden to GC. `sync.Pool` can cache objects that are not used temporarily and use them directly (without reallocation) when they are needed next time. This can potentially reduce the GC workload and improve performance.

#### How to use sync.Pool?
First, you need to set the `New` function. This function will be used when there is no cached object in the Pool. After that you only need to use `Get` and `Put` methods to retrieve and return objects. Also, a Pool must not be copied after first use.

Due to `New` function type, which is `func() interface{}`, `Get` method returns an `interface{}`. So you need to do a type assertion in order to get the concrete object.
```go
// A dummy struct
type Person struct {
	Name string
}

// Initializing pool
var personPool = sync.Pool{
	// New optionally specifies a function to generate
	// a value when Get would otherwise return nil.
	New: func() interface{} { return new(Person) },
}

// Main function
func main() {
	// Get hold of an instance
	newPerson := personPool.Get().(*Person)
	// Defer release function
	// After that the same instance is 
	// reusable by another routine
	defer personPool.Put(newPerson)

	// Using the instance
	newPerson.Name = "Jack"
}
```

#### How does sync.Pool work?
`sync.Pool` has two containers for objects: local pool (active) and victim cache (archived).

According to the `sync/pool.go` , package `init` function registers to the runtime as a method to clean the pools. This method will be triggered by the GC.
```go
func init() {  
	runtime_registerPoolCleanup(poolCleanup)  
}
```
When the GC is triggered, objects inside the victim cache will be collected and then objects inside the local pool will be moved to the victim cache.
```go
func poolCleanup() {  
	// Drop victim caches from all pools.  
	for _, p := range oldPools {  
		p.victim = nil  
		p.victimSize = 0  
	}  
	  
	// Move primary cache to victim cache.  
	for _, p := range allPools {  
		p.victim = p.local  
		p.victimSize = p.localSize  
		p.local = nil  
		p.localSize = 0  
	}  
	  
	oldPools, allPools = allPools, nil  
}
```
New objects are put in the local pool. Calling `Put` method will put the object into the local pool as well. Calling `Get` method will take an object from the victim cache in the first place and if the victim cache was empty the object will be taken from the local pool.
![[sync_pool.gif]]

### sync.Map
